{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03d454c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d9f5b5",
   "metadata": {},
   "source": [
    "## Load and Prepare data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a96728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train are :  [5 0 4 ... 5 6 8]\n",
      "X_train are :  [[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n",
      "\n",
      "\n",
      "\n",
      "Shape of X_train :  (60000, 28, 28)\n",
      "Shape of y_test  :  (60000,)\n",
      "Which means 60000 images \n",
      "Height of  each image : 28px  \n",
      "Width each image : 28px\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train,y_train) , (x_test,y_test) = mnist.load_data()\n",
    "\n",
    "print(\"y_train are : \",y_train)\n",
    "print(\"X_train are : \",x_train[:2])\n",
    "print(\"\\n\\n\")\n",
    "print(\"Shape of X_train : \",x_train.shape)\n",
    "print(\"Shape of y_test  : \",y_train.shape)\n",
    "print(\"Which means 60000 images \\nHeight of  each image : 28px  \\nWidth each image : 28px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90aa8d2",
   "metadata": {},
   "source": [
    "now we need normalize pixel values to 0-1 range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a4a3d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test  = x_test.astype('float32') / 255.0 \n",
    "\n",
    "x_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c361cd",
   "metadata": {},
   "source": [
    "we know that Ann only support 1d array        minist is 2d data so need chnage the shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "181cfa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After change of shape :  (60000, 784)\n",
      "X_train look like \n",
      "  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(-1,784)      #-1 fill automaticly no of rows(60k) numpy feature\n",
    "x_test  = x_test.reshape(-1,784) # new width of each data\n",
    "\n",
    "print(\"After change of shape : \",x_train.shape)\n",
    "print(\"X_train look like \\n \",x_train[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c227066",
   "metadata": {},
   "source": [
    "### Bulding a ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06ad5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(784,)), #input layer\n",
    "    tf.keras.layers.Dense(300,activation='relu'), # hidden layer\n",
    "    tf.keras.layers.Dense(10,activation='softmax') # Output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "032080d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"\"\"Input Layer:\n",
    "\n",
    "Shape: (784,)\n",
    "It accepts 784 features (flattened 28x28 image).\n",
    "----------------------------------------------------------------------\n",
    "Hidden Layer (Dense Layer with 128 neurons):\n",
    "\n",
    "Neurons: 128\n",
    "Activation: ReLU\n",
    "This layer transforms the input data into a higher-dimensional space, allowing the model to learn complex features.\n",
    "apply weight and bias \n",
    "----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Output Layer (Dense Layer with 10 neurons):\n",
    "\n",
    "Neurons: 10\n",
    "Activation: Softmax\n",
    "This layer outputs the final probabilities for each of the 10 classes (digits 0-9).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3122e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                3010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 238,510\n",
      "Trainable params: 238,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e59df23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters = 101770\n",
      "Weights in Hidden Layer = 100352\n",
      "Biases in Hidden Layer = 128\n",
      "Weights in Output Layer = 1280\n",
      "Biases in Output Layer = 10\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_size = 128\n",
    "output_size = 10\n",
    "\n",
    "w_hidden = input_size * hidden_size\n",
    "b_hidden = hidden_size\n",
    "total_hidden = w_hidden + b_hidden\n",
    "\n",
    "w_output = hidden_size * output_size\n",
    "b_output = output_size\n",
    "total_output = w_output + b_output\n",
    "\n",
    "total_params = total_hidden + total_output\n",
    "\n",
    "print(f\"Total Parameters = {total_params}\")\n",
    "print(f\"Weights in Hidden Layer = {w_hidden}\")\n",
    "print(f\"Biases in Hidden Layer = {b_hidden}\")\n",
    "print(f\"Weights in Output Layer = {w_output}\")\n",
    "print(f\"Biases in Output Layer = {b_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6b1a80",
   "metadata": {},
   "source": [
    "#### Lets apply  loss function,optimizer and evalution metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a14dfc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled........\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "loss = 'sparse_categorical_crossentropy',\n",
    "optimizer = 'sgd',\n",
    "metrics = ['accuracy']\n",
    ")\n",
    "print(\"Model compiled........\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd55456",
   "metadata": {},
   "source": [
    "#### Lets train our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afb19c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6244 - accuracy: 0.8460 - val_loss: 0.3453 - val_accuracy: 0.9084\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3283 - accuracy: 0.9084 - val_loss: 0.2853 - val_accuracy: 0.9210\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2798 - accuracy: 0.9223 - val_loss: 0.2499 - val_accuracy: 0.9322\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2487 - accuracy: 0.9311 - val_loss: 0.2275 - val_accuracy: 0.9345\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2249 - accuracy: 0.9379 - val_loss: 0.2077 - val_accuracy: 0.9417\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2053 - accuracy: 0.9427 - val_loss: 0.1917 - val_accuracy: 0.9463\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1895 - accuracy: 0.9476 - val_loss: 0.1797 - val_accuracy: 0.9488\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1758 - accuracy: 0.9511 - val_loss: 0.1696 - val_accuracy: 0.9500\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1643 - accuracy: 0.9538 - val_loss: 0.1585 - val_accuracy: 0.9529\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1544 - accuracy: 0.9567 - val_loss: 0.1498 - val_accuracy: 0.9560\n",
      "Model Training is completed...\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,epochs=10,batch_size=32,validation_data=(x_test,y_test),verbose=1)\n",
    "print(\"Model Training is completed...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dbe218",
   "metadata": {},
   "source": [
    "#### Model evalution and make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c52685b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1498 - accuracy: 0.9560\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_accuracy = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6daaf007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss :  0.14981237053871155\n",
      "Test accuracy : 0.9560\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Loss : \",test_loss)\n",
    "print(\"Test accuracy : {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3e47f8",
   "metadata": {},
   "source": [
    "Test loss = It store loss of the model on test data after evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3d27d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n",
      "Prediction vs True Label\n",
      "Sample1 : Predicted = 7, True_label = 7\n",
      "Sample2 : Predicted = 2, True_label = 2\n",
      "Sample3 : Predicted = 1, True_label = 1\n",
      "Sample4 : Predicted = 0, True_label = 0\n",
      "Sample5 : Predicted = 4, True_label = 4\n"
     ]
    }
   ],
   "source": [
    "## Make prediction\n",
    "\n",
    "t_sample = x_test[:5]\n",
    "pred = model.predict(t_sample)\n",
    "pred_label = np.argmax(pred,axis=1)\n",
    "true_label = y_test[:5]\n",
    "\n",
    "print(\"Prediction vs True Label\")\n",
    "for i in range(5):\n",
    "    print(f\"Sample{i+1} : Predicted = {pred_label[i]}, True_label = {true_label[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef406b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2972f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLenv",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
